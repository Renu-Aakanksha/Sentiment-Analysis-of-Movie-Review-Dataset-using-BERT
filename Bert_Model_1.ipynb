{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - BERT model\n",
    "NLP - Sentimental Analysis of \"Large Movie Review Dataset\" using LSTM network\n",
    "\n",
    "CSE - 6363 - 003 : Machine Learning \n",
    "\n",
    "Team - 18 : Members -\n",
    "Preeti Singh - 1002013566\n",
    "Sai Sarath Reddy Koppula - 1002081785\n",
    "Renu Aakanksha Veesam - 1002113666"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F0vEsoxSyEhI"
   },
   "source": [
    "# For Implementing BERT Model we have followed this Blog Post by Tensorflow as reference.\n",
    "\n",
    "- Ref.: https://www.tensorflow.org/text/tutorials/classify_text_with_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FgUo03ahyDWm"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ydKR31JMya0a",
    "outputId": "86f9ef57-5409-49c4-d577-d2d22f54a53b"
   },
   "outputs": [],
   "source": [
    "# Downloading the IMDB Dataset\n",
    "# The IMDB Dataset is hosted on Stanford Website - 'https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz'\n",
    "\n",
    "# Passing the IMDB Dataset Download link and Downloading it using the keras utils.get_file method\n",
    "imdb_data = tf.keras.utils.get_file(\"aclImdb_v1.tar.gz\", \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\", untar=True, cache_dir=\".\", cache_subdir=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQisPTDDzONP"
   },
   "outputs": [],
   "source": [
    "# The original dataset is in a folder format, the following code is to handle these folder format that the original dataset is in\n",
    "main_directory = os.path.join(os.path.dirname(imdb_data), 'aclImdb')\n",
    "\n",
    "# Training Data Directory\n",
    "training_data_directory = os.path.join(main_directory, \"train\")\n",
    "\n",
    "# Removing the folders that are not used.\n",
    "shutil.rmtree(os.path.join(training_data_directory, \"unsup\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBZw-J9i0Zl4",
    "outputId": "d43facd2-8c2d-4e74-d5ef-ac5beedbbb70"
   },
   "outputs": [],
   "source": [
    "# Loading the training and testing data\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "\n",
    "# This function is typically used for creating a labeled dataset of text data from a directory structure.\n",
    "raw_train_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/train', batch_size=batch_size, validation_split=0.2, subset='training', seed=seed)\n",
    "class_names = raw_train_ds.class_names\n",
    "train_ds = raw_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "\n",
    "# Testing Dataset\n",
    "test_ds = tf.keras.utils.text_dataset_from_directory('aclImdb/test', batch_size=batch_size)\n",
    "test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I2RQfpJE1BJ8"
   },
   "outputs": [],
   "source": [
    "# Using the Small-BERT Model\n",
    "# Loading the Preprocessing Component\n",
    "bert_preprocess_model = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TESb0duM3Ffg"
   },
   "outputs": [],
   "source": [
    "# Using the Small-BERT Model\n",
    "# Loading the BERT Model\n",
    "bert_model = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IWQbvegI3nHA"
   },
   "outputs": [],
   "source": [
    "def get_BERT_classifier_model():\n",
    "  # Text Input Layer\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  # Text Preprocessing Layer\n",
    "  preprocessing_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3', name='preprocessing')\n",
    "\n",
    "  # Text Encoding\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "\n",
    "  # Text Encoding Layer\n",
    "  encoder = hub.KerasLayer('https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1', trainable=True, name='BERT_encoder')\n",
    "\n",
    "  # Obtain the Encoder Output\n",
    "  outputs = encoder(encoder_inputs)\n",
    "\n",
    "  net = outputs['pooled_output']\n",
    "\n",
    "  # Adding a Dropout Layer\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "\n",
    "  # Final Prediction Layer\n",
    "  net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "\n",
    "  # Input till the Dense Prediction Layers are combined as a Keras Model\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzfxKRKe4e4L"
   },
   "outputs": [],
   "source": [
    "# Creating the model object\n",
    "model = get_BERT_classifier_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jD-p_LtV4vpP"
   },
   "source": [
    "Model Architecture Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "SCK9Viqw4yK5",
    "outputId": "7e69d413-f57f-4cc2-89f4-a75336761687"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3FLlrnaJ5DBZ"
   },
   "outputs": [],
   "source": [
    "# Training the Model for 10 epochs\n",
    "epochs = 10\n",
    "\n",
    "steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "# Learning rate of 0.00003\n",
    "init_lr = 3e-5\n",
    "\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr, num_train_steps=num_train_steps, num_warmup_steps=num_warmup_steps, optimizer_type='adamw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGTQP27u5OqX"
   },
   "outputs": [],
   "source": [
    "# Using the BinaryCrossEntropy Loss - as we are doing sentiment prediction with two classes\n",
    "# Using Accuracy as a metric\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.BinaryCrossentropy(from_logits=True), metrics=tf.metrics.BinaryAccuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WQ26VPRU5c4X",
    "outputId": "5ecb728a-484c-4dfc-ddeb-1df811ddc010"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x=train_ds, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w1NrZMHt5jpt",
    "outputId": "dfd257d2-aad4-4894-e388-4c0c34f8693a"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "\n",
    "print(f'Loss: {loss}')\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QGDQeqeb9xJs"
   },
   "outputs": [],
   "source": [
    "# Example Prediction with BERT\n",
    "examples = ['this is such a terrible movie, we had a aweful experience. The direction is bad and the movie run time was too long.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ukqi1cIU-kut"
   },
   "outputs": [],
   "source": [
    "results = tf.sigmoid(model(tf.constant(examples)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aGJ4eXht-pn2",
    "outputId": "90e8c0ec-4ae0-4000-f46a-d42b9d55b378"
   },
   "outputs": [],
   "source": [
    "print(results[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA_zk9_s_DBA"
   },
   "source": [
    "# From the result it can be seen that the provided example belongs to the negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "id": "cyEy1Sky-wPA",
    "outputId": "f744cb57-aef2-46ab-e74e-a14aae795bd1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history[\"loss\"], marker=\"x\", color=\"blue\")\n",
    "plt.title(\"Epoch-wise Training Loss Scores\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history[\"binary_accuracy\"], marker=\"x\", color=\"blue\")\n",
    "plt.title(\"Epoch-wise Training Accuracy Scores\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
